1:"$Sreact.fragment"
2:I[3719,["408","static/chunks/408-464634266c54e89f.js","874","static/chunks/874-7c5eb7db8d3a51f7.js","55","static/chunks/55-328b1d72b5e3e498.js","177","static/chunks/app/layout-fbe39f4a18972378.js"],"ThemeProvider"]
3:I[768,["408","static/chunks/408-464634266c54e89f.js","874","static/chunks/874-7c5eb7db8d3a51f7.js","55","static/chunks/55-328b1d72b5e3e498.js","177","static/chunks/app/layout-fbe39f4a18972378.js"],"default"]
4:I[7555,[],""]
5:I[1295,[],""]
6:I[2548,["408","static/chunks/408-464634266c54e89f.js","874","static/chunks/874-7c5eb7db8d3a51f7.js","55","static/chunks/55-328b1d72b5e3e498.js","177","static/chunks/app/layout-fbe39f4a18972378.js"],"default"]
8:I[9665,[],"MetadataBoundary"]
a:I[9665,[],"OutletBoundary"]
d:I[4911,[],"AsyncMetadataOutlet"]
f:I[9665,[],"ViewportBoundary"]
11:I[6614,[],""]
:HL["/_next/static/css/51bc899147ec0689.css","style"]
0:{"P":null,"b":"I3sq1dxlKFClGm3POGcHm","p":"","c":["","publications",""],"i":false,"f":[[["",{"children":[["slug","publications","d"],{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/51bc899147ec0689.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/fav.png","type":"image/svg+xml"}],["$","link",null,{"rel":"dns-prefetch","href":"https://google-fonts.jialeliu.com"}],["$","link",null,{"rel":"preconnect","href":"https://google-fonts.jialeliu.com","crossOrigin":""}],["$","link",null,{"rel":"preload","as":"style","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}],["$","link",null,{"rel":"stylesheet","id":"gfonts-css","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap","media":"print"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function(){\n                var l = document.getElementById('gfonts-css');\n                if (!l) return;\n                if (l.media !== 'all') {\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\n                }\n              })();\n            "}}],["$","noscript",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}]}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              try {\n                const theme = localStorage.getItem('theme-storage');\n                const parsed = theme ? JSON.parse(theme) : null;\n                const setting = parsed?.state?.theme || 'system';\n                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\n                var root = document.documentElement;\n                root.classList.add(effective);\n                root.setAttribute('data-theme', effective);\n              } catch (e) {\n                var root = document.documentElement;\n                root.classList.add('light');\n                root.setAttribute('data-theme', 'light');\n              }\n            "}}]]}],["$","body",null,{"className":"font-sans antialiased","children":["$","$L2",null,{"children":[["$","$L3",null,{"items":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"},{"title":"Teaching","type":"page","target":"teaching","href":"/teaching"},{"title":"Awards","type":"page","target":"awards","href":"/awards"},{"title":"Services","type":"page","target":"services","href":"/services"},{"title":"CV","type":"page","target":"cv","href":"/cv"}],"siteTitle":"Zhongsheng Wang 王钟声","enableOnePageMode":false}],["$","main",null,{"className":"min-h-screen pt-16 lg:pt-20","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{"lastUpdated":"February 15, 2026"}]]}]}]]}]]}],{"children":[["slug","publications","d"],["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L7",["$","$L8",null,{"children":"$L9"}],null,["$","$La",null,{"children":["$Lb","$Lc",["$","$Ld",null,{"promise":"$@e"}]]}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","URimUsALtBzrQ9ZlsMZCg",{"children":[["$","$Lf",null,{"children":"$L10"}],null]}],null]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:"$Sreact.suspense"
13:I[4911,[],"AsyncMetadata"]
15:I[6669,["408","static/chunks/408-464634266c54e89f.js","63","static/chunks/63-0d5ebfce210dba9a.js","486","static/chunks/486-d2ce1eaba6fd711e.js","147","static/chunks/147-9a4bc6658f595514.js","748","static/chunks/748-bce208fe0b98aa28.js","182","static/chunks/app/%5Bslug%5D/page-40b7813e1f862592.js"],"default"]
9:["$","$12",null,{"fallback":null,"children":["$","$L13",null,{"promise":"$@14"}]}]
16:T4f7,Text‑to‑image models are rapidly advancing into creative practice and increasingly support generating illustrated storybooks, i.e., sequential and image‑based narratives conditioned on written text. Previous surveys have examined challenges in video coherence or single‑image fidelity; however, no comprehensive review addresses the unique requirements of storybook illustration. This survey fills this gap by grounding AI‑illustrated storybook generation in a narratology framework. Specifically, it introduces a six‑dimensional consistency model encompassing time, space, character, event and plot, style and theme. For each dimension the authors consolidate definitions, representative methods, datasets and evaluation metrics, mapping the current landscape of the field. Building on this analysis they further identify cross‑dimensional failure modes and limitations of current approaches. Finally, the survey proposes potential future research directions, including the development of book‑scale integrated evaluation systems tailored for illustrated storybooks, more robust and controllable generation pipelines, enhanced multimodal semantic–visual alignment mechanisms and the establishment of reader‑oriented safety and educational guidelines.17:T6d2,@article{lin2026narratology,
  title = {Narratology meets text-to-image: a survey of consistency in AI generated storybook illustrations},
  author = {Lin, Zhedong and Wang, Zhongsheng and Liu, Qian and Zhang, Xinyu and Liu, Jiamou},
  year = {2026},
  journal = {Artificial Intelligence Review},
  publisher = {Springer},
  type = {journal},
  status = {published},
  researchArea = {machine-learning},
  abstract = {Text‑to‑image models are rapidly advancing into creative practice and increasingly support generating illustrated storybooks, i.e., sequential and image‑based narratives conditioned on written text. Previous surveys have examined challenges in video coherence or single‑image fidelity; however, no comprehensive review addresses the unique requirements of storybook illustration. This survey fills this gap by grounding AI‑illustrated storybook generation in a narratology framework. Specifically, it introduces a six‑dimensional consistency model encompassing time, space, character, event and plot, style and theme. For each dimension the authors consolidate definitions, representative methods, datasets and evaluation metrics, mapping the current landscape of the field. Building on this analysis they further identify cross‑dimensional failure modes and limitations of current approaches. Finally, the survey proposes potential future research directions, including the development of book‑scale integrated evaluation systems tailored for illustrated storybooks, more robust and controllable generation pipelines, enhanced multimodal semantic–visual alignment mechanisms and the establishment of reader‑oriented safety and educational guidelines.},
  doi = {https://doi.org/10.1007/s10462-025-11482-6}
}18:T67f,@inproceedings{li-etal-2025-llm-based-business,
  title = {LLM-based Business Process Models Generation from Textual Descriptions},
  author = {Li, Xiaoxuan and Ni, Lin and Wang, Xin and Yitong, Tang and Li, Ruoxuan and Liu, Jiamou and Wang, Zhongsheng},
  year = {2025},
  month = {12},
  type = {conference},
  status = {published},
  researchArea = {machine-learning},
  booktitle = {Proceedings of the 14th International Joint Conference on Natural Language Processing and the 4th Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics},
  pages = {523--533},
  url = {https://aclanthology.org/2025.findings-ijcnlp.31/},
  abstract = {Business process modeling has traditionally depended on manual efforts or rigid rule-based techniques, limiting scalability and flexibility. Recent progress in Large Language Models (LLMs) enables automatic generation of process models from text, yet a systematic evaluation remains lacking. This paper explores the ability of LLMs to produce structurally and semantically valid business process workflows using five approaches: zero-shot, zero-shot CoT, few-shot, few-shot CoT, and fine-tuning. We assess performance under increasing control-flow complexity (e.g., nested gateways, parallel branches) using the MaD dataset, and introduce a masked-input setting to test semantic robustness. Results show that while fine-tuning achieves the best accuracy, few-shot CoT excels in handling complex logic and incomplete inputs. These findings reveal the strengths and limits of LLMs in process modeling and offer practical guidance for enterprise Business Process Management (BPM) automation.}
}19:T4ab,We present R-Debater, an agentic framework for generating multi-turn debates built on argumentative memory. Grounded in rhetoric and memory studies, the system views debate as a process of recalling and adapting prior arguments to maintain stance consistency, respond to opponents, and support claims with evidence. Specifically, R-Debater integrates a debate knowledge base for retrieving case-like evidence and prior debate moves with a role-based agent that composes coherent utterances across turns. We evaluate on standardized ORCHID debates, constructing a 1,000-item retrieval corpus and a held-out set of 32 debates across seven domains. Two tasks are evaluated: next-utterance generation, assessed by InspireScore (subjective, logical, and factual), and adversarial multi-turn simulations, judged by Debatrix (argument, source, language, and overall). Compared with strong LLM baselines, R-Debater achieves higher single-turn and multi-turn scores. Human evaluation with 20 experienced debaters further confirms its consistency and evidence use, showing that combining retrieval grounding with structured planning yields more faithful, stance-aligned, and coherent debates across turns.1a:T614,@inproceedings{li2025r,
  title = {R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory},
  author = {Li, Maoyuan and Wang, Zhongsheng and Li, Haoyuan and Liu, Jiamou},
  year = {2025},
  type = {conference},
  status = {published},
  researchArea = {machine-learning},
  booktitle = {arXiv preprint arXiv:2512.24684},
  abstract = {We present R-Debater, an agentic framework for generating multi-turn debates built on argumentative memory. Grounded in rhetoric and memory studies, the system views debate as a process of recalling and adapting prior arguments to maintain stance consistency, respond to opponents, and support claims with evidence. Specifically, R-Debater integrates a debate knowledge base for retrieving case-like evidence and prior debate moves with a role-based agent that composes coherent utterances across turns. We evaluate on standardized ORCHID debates, constructing a 1,000-item retrieval corpus and a held-out set of 32 debates across seven domains. Two tasks are evaluated: next-utterance generation, assessed by InspireScore (subjective, logical, and factual), and adversarial multi-turn simulations, judged by Debatrix (argument, source, language, and overall). Compared with strong LLM baselines, R-Debater achieves higher single-turn and multi-turn scores. Human evaluation with 20 experienced debaters further confirms its consistency and evidence use, showing that combining retrieval grounding with structured planning yields more faithful, stance-aligned, and coherent debates across turns.}
}1b:T6e7,@inproceedings{10.1145/3743093.3770985,
  title = {CharCom: Composable Identity Control for Multi-Character Story Illustration},
  author = {Wang, Zhongsheng and Lin, Ming and Lin, Zhedong and Shakib, Yaser and Liu, Qian and Liu, Jiamou},
  year = {2025},
  type = {conference},
  status = {published},
  tags = {Text-to-Image Generation, Diffusion Models, Low-Rank Adaptation, Adapter Composition, Identity Control},
  researchArea = {machine-learning},
  booktitle = {Proceedings of the 7th ACM International Conference on Multimedia in Asia},
  doi = {10.1145/3743093.3770985},
  url = {https://doi.org/10.1145/3743093.3770985},
  abstract = {Ensuring character identity consistency across varying prompts remains a fundamental limitation in diffusion-based text-to-image generation. We propose CharCom, a modular and parameter-efficient framework that achieves character-consistent story illustration through composable LoRA adapters, enabling efficient per-character customization without retraining the base model. Built on a frozen diffusion backbone, CharCom dynamically composes adapters at inference using prompt-aware control. Experiments on multi-scene narratives demonstrate that CharCom significantly enhances character fidelity, semantic alignment, and temporal coherence. It remains robust in crowded scenes and enables scalable multi-character generation with minimal overhead, making it well-suited for real-world applications such as story illustration and animation.},
  video = {https://www.bilibili.com/video/BV1armaBhEHZ/?spm_id_from=333.1387.upload.video_card.click},
  isbn = {9798400720055},
  address = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series = {MMAsia '25},
  articleno = {41},
  numpages = {7}
}1c:T479,Large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated impressive capabilities in various generative tasks. However, their performance is often hampered by limitations in accessing and leveraging long-term memory, leading to specific vulnerabilities and biases, especially during long interactions. This paper introduces ChatLogic, an innovative framework specifically targeted at LLM reasoning tasks that can enhance the performance of LLMs in multi-step deductive reasoning tasks by integrating logic programming. In ChatLogic, the language model plays a central role, acting as a controller and participating in every system operation stage. We propose a novel method of converting logic problems into symbolic integration with an inference engine. This approach leverages large language models' situational understanding and imitation skills and uses symbolic memory to enhance multi-step deductive reasoning capabilities. Our results show that the ChatLogic framework significantly improves the multi-step reasoning capabilities of LLMs. The source code and data are available at https://github.com/Strong-AI-Lab/ChatLogic1d:T70c,@inproceedings{wang2024chatlogic,
  title = {Chatlogic: Integrating logic programming with large language models for multi-step reasoning},
  author = {Wang, Zhongsheng and Liu, Jiamou and Bao, Qiming and Rong, Hongfei and Zhang, Jingfeng},
  year = {2024},
  type = {conference},
  status = {published},
  researchArea = {machine-learning},
  booktitle = {2024 International Joint Conference on Neural Networks (IJCNN)},
  pages = {1--8},
  doi = {10.1109/IJCNN60899.2024.10650138},
  url = {https://ieeexplore.ieee.org/document/10650138?denied=},
  abstract = {Large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated impressive capabilities in various generative tasks. However, their performance is often hampered by limitations in accessing and leveraging long-term memory, leading to specific vulnerabilities and biases, especially during long interactions. This paper introduces ChatLogic, an innovative framework specifically targeted at LLM reasoning tasks that can enhance the performance of LLMs in multi-step deductive reasoning tasks by integrating logic programming. In ChatLogic, the language model plays a central role, acting as a controller and participating in every system operation stage. We propose a novel method of converting logic problems into symbolic integration with an inference engine. This approach leverages large language models' situational understanding and imitation skills and uses symbolic memory to enhance multi-step deductive reasoning capabilities. Our results show that the ChatLogic framework significantly improves the multi-step reasoning capabilities of LLMs. The source code and data are available at https://github.com/Strong-AI-Lab/ChatLogic},
  slides = {ChatLogicSlides.pdf},
  poster = {ChatLogicPoster.pdf},
  organization = {IEEE}
}1e:T49d,In an era where the capabilities of large language models (LLM) like ChatGPT are transforming digital communication, the challenge of directing these tools to create extensive, coherent narratives on an epic-scale has emerged as a critical frontier. This study introduces a novel methodology that fuses the spontaneous story generation of LLMs with the precision of auto-prompted reinforcement learning for crafting epic-scale, coherent narratives. Our approach starts with generating a skeletal outline, followed by iterative expansion, and blending operations for maintaining structural coherence in long-form content. To train the reinforcement learning model efficiently, we introduce an environment simulator that leverages a database of historical LLM interactions, circumventing the limitations of direct LLM interactions. This method enhances the decision-making process of the RL agent, enabling more effective prompt selection and narrative flow in extended texts. We validate its effectiveness through experiments, demonstrating the model's ability to generate structured, narrative-driven text, thereby setting a new pathway towards AI-driven, large-scale storytelling.1f:T73a,@inproceedings{10650358,
  title = {Epic-Level Text Generation with LLM through Auto-prompted Reinforcement Learning},
  author = {Qi, Qianqian and Ni, Lin and Wang, Zhongsheng and Zhang, Libo and Liu, Jiamou and Witbrock, Michael},
  year = {2024},
  type = {conference},
  status = {published},
  tags = {Systematics, Fuses, Large language models, Refining, Neural networks, Reinforcement learning, Writing, GPT-3.5, story generation, reinforcement learning, auto-prompt},
  researchArea = {neural-networks},
  booktitle = {2024 International Joint Conference on Neural Networks (IJCNN)},
  pages = {1-8},
  doi = {10.1109/IJCNN60899.2024.10650358},
  abstract = {In an era where the capabilities of large language models (LLM) like ChatGPT are transforming digital communication, the challenge of directing these tools to create extensive, coherent narratives on an epic-scale has emerged as a critical frontier. This study introduces a novel methodology that fuses the spontaneous story generation of LLMs with the precision of auto-prompted reinforcement learning for crafting epic-scale, coherent narratives. Our approach starts with generating a skeletal outline, followed by iterative expansion, and blending operations for maintaining structural coherence in long-form content. To train the reinforcement learning model efficiently, we introduce an environment simulator that leverages a database of historical LLM interactions, circumventing the limitations of direct LLM interactions. This method enhances the decision-making process of the RL agent, enabling more effective prompt selection and narrative flow in extended texts. We validate its effectiveness through experiments, demonstrating the model's ability to generate structured, narrative-driven text, thereby setting a new pathway towards AI-driven, large-scale storytelling.}
}20:T4c0,In fine‑tuning large language models, conserving computational resources while maintaining effectiveness and improving outcomes within the same computational constraints is crucial. The Low‑Rank Adaptation (LoRA) strategy balances efficiency and performance by reducing the number of trainable parameters and computational costs. However, most work on LoRA focuses on fine‑tuning methodologies without exploring further compression. Since many of LoRA's parameters may still be superfluous, they can lead to unnecessary resource consumption. This paper proposes CoRA, which leverages shared knowledge to optimize LoRA training by substituting its matrix B with a common subspace from large models. Two approaches are explored: (1) freezing the substitute matrix to halve parameters while training the remaining matrix for specific tasks and (2) using the substitute matrix as an enhanced initial state for the original matrix, achieving improved results with the same number of parameters. Experiments show that the first approach matches the efficacy of original LoRA fine‑tuning while being more efficient, and the second approach yields further improvements, demonstrating the effectiveness of the method.21:T665,@inproceedings{xiao2024cora,
  title = {Cora: Optimizing low-rank adaptation with common subspace of large language models},
  author = {Xiao, Xiaojun and Shen, Sen and Bao, Qiming and Rong, Hongfei and Liu, Kairui and Wang, Zhongsheng and Liu, Jiamou},
  year = {2024},
  type = {conference},
  status = {published},
  researchArea = {machine-learning},
  booktitle = {arXiv preprint arXiv:2409.02119},
  abstract = {In fine‑tuning large language models, conserving computational resources while maintaining effectiveness and improving outcomes within the same computational constraints is crucial. The Low‑Rank Adaptation (LoRA) strategy balances efficiency and performance by reducing the number of trainable parameters and computational costs. However, most work on LoRA focuses on fine‑tuning methodologies without exploring further compression. Since many of LoRA's parameters may still be superfluous, they can lead to unnecessary resource consumption. This paper proposes CoRA, which leverages shared knowledge to optimize LoRA training by substituting its matrix B with a common subspace from large models. Two approaches are explored: (1) freezing the substitute matrix to halve parameters while training the remaining matrix for specific tasks and (2) using the substitute matrix as an enhanced initial state for the original matrix, achieving improved results with the same number of parameters. Experiments show that the first approach matches the efficacy of original LoRA fine‑tuning while being more efficient, and the second approach yields further improvements, demonstrating the effectiveness of the method.}
}22:T597,@inproceedings{wang2024weak,
  title = {Weak Supervision Techniques towards Enhanced ASR Models in Industry-level CRM Systems},
  author = {Wang, Zhongsheng and Wang, Sijie and Wang, Jia and Liang, Yung-I and Zhang, Yuxi and Liu, Jiamou},
  year = {2024},
  type = {conference},
  status = {published},
  researchArea = {machine-learning},
  booktitle = {International Conference on Neural Information Processing},
  pages = {138--152},
  abstract = {In the design of customer relationship management (CRM) systems, accurately identifying customer types and offering personalized services are key to enhancing customer satisfaction and loyalty. However, this process faces the challenge of discerning customer voices and intentions, and general pre‑trained automatic speech recognition (ASR) models make it difficult to effectively address industry‑specific speech recognition tasks. To address this issue the authors propose a solution for fine‑tuning industry‑specific ASR models using weak supervision, which significantly improves the performance of the fine‑tuned ASR models in industry applications. Experimental results show that this method substantially improves the crucial auxiliary role of the ASR model in industry CRM systems, and the approach has also been adopted in actual industrial applications.},
  slides = {ICONIP2024Slides.pdf},
  doi = {10.1007/978-981-96-7036-9_10},
  organization = {Springer}
}7:["$","div",null,{"className":"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12","children":[["$","$L15",null,{"config":{"type":"publication","title":"Publications","description":"A collection of my research work.","source":"publications.bib"},"publications":[{"id":"lin2026narratology","title":"Narratology meets text-to-image: a survey of consistency in AI generated storybook illustrations","authors":[{"name":"Zhedong Lin","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zhongsheng Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Qian Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xinyu Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiamou Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2026,"type":"journal","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:0:tags","researchArea":"machine-learning","journal":"Artificial Intelligence Review","conference":"","doi":"https://doi.org/10.1007/s10462-025-11482-6","abstract":"$16","description":"Provides a comprehensive survey that grounds AI‑generated storybook illustration in narratology, defining six dimensions of consistency and reviewing methods, datasets, metrics and challenges across time, space, character, plot, style and theme.","selected":true,"bibtex":"$17"},{"id":"li-etal-2025-llm-based-business","title":"LLM-based Business Process Models Generation from Textual Descriptions","authors":[{"name":"Xiaoxuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Lin Ni","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xin Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Tang Yitong","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Ruoxuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiamou Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zhongsheng Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"month":"12","type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:1:tags","researchArea":"machine-learning","journal":"","conference":"Proceedings of the 14th International Joint Conference on Natural Language Processing and the 4th Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics","pages":"523--533","url":"https://aclanthology.org/2025.findings-ijcnlp.31/","abstract":"Business process modeling has traditionally depended on manual efforts or rigid rule-based techniques, limiting scalability and flexibility. Recent progress in Large Language Models (LLMs) enables automatic generation of process models from text, yet a systematic evaluation remains lacking. This paper explores the ability of LLMs to produce structurally and semantically valid business process workflows using five approaches: zero-shot, zero-shot CoT, few-shot, few-shot CoT, and fine-tuning. We assess performance under increasing control-flow complexity (e.g., nested gateways, parallel branches) using the MaD dataset, and introduce a masked-input setting to test semantic robustness. Results show that while fine-tuning achieves the best accuracy, few-shot CoT excels in handling complex logic and incomplete inputs. These findings reveal the strengths and limits of LLMs in process modeling and offer practical guidance for enterprise Business Process Management (BPM) automation.","description":"","selected":false,"bibtex":"$18"},{"id":"li2025r","title":"R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory","authors":[{"name":"Maoyuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zhongsheng Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Haoyuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiamou Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:2:tags","researchArea":"machine-learning","journal":"","conference":"arXiv preprint arXiv:2512.24684","abstract":"$19","description":"This article employs a multi-agent simulation approach, combined with relevant theoretical methods from debate, to implement an enhanced debate task, thereby improving the reliability of debate content.","selected":false,"preview":"R-debater.png","bibtex":"$1a"},{"id":"10.1145/3743093.3770985","title":"CharCom: Composable Identity Control for Multi-Character Story Illustration","authors":[{"name":"Zhongsheng Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Ming Lin","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zhedong Lin","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yaser Shakib","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Qian Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiamou Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:3:tags","researchArea":"machine-learning","journal":"","conference":"Proceedings of the 7th ACM International Conference on Multimedia in Asia","doi":"10.1145/3743093.3770985","url":"https://doi.org/10.1145/3743093.3770985","abstract":"Ensuring character identity consistency across varying prompts remains a fundamental limitation in diffusion-based text-to-image generation. We propose CharCom, a modular and parameter-efficient framework that achieves character-consistent story illustration through composable LoRA adapters, enabling efficient per-character customization without retraining the base model. Built on a frozen diffusion backbone, CharCom dynamically composes adapters at inference using prompt-aware control. Experiments on multi-scene narratives demonstrate that CharCom significantly enhances character fidelity, semantic alignment, and temporal coherence. It remains robust in crowded scenes and enables scalable multi-character generation with minimal overhead, making it well-suited for real-world applications such as story illustration and animation.","description":"","selected":true,"preview":"ACMMMASIA2025.png","bibtex":"$1b"},{"id":"wang2024chatlogic","title":"Chatlogic: Integrating logic programming with large language models for multi-step reasoning","authors":[{"name":"Zhongsheng Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiamou Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Qiming Bao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hongfei Rong","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jingfeng Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:4:tags","researchArea":"machine-learning","journal":"","conference":"2024 International Joint Conference on Neural Networks (IJCNN)","pages":"1--8","doi":"10.1109/IJCNN60899.2024.10650138","url":"https://ieeexplore.ieee.org/document/10650138?denied=","code":"https://github.com/Strong-AI-Lab/ChatLogic","abstract":"$1c","description":"This paper proposes a bidirectional transformation method that converts natural language inference into logical code to enhance the multi-step reasoning ability of LLM.","selected":true,"preview":"chatlogic.png","bibtex":"$1d"},{"id":"10650358","title":"Epic-Level Text Generation with LLM through Auto-prompted Reinforcement Learning","authors":[{"name":"Qianqian Qi","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Lin Ni","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zhongsheng Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Libo Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiamou Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Michael Witbrock","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:5:tags","researchArea":"machine-learning","journal":"","conference":"2024 International Joint Conference on Neural Networks (IJCNN)","pages":"1-8","doi":"10.1109/IJCNN60899.2024.10650358","abstract":"$1e","description":"This article implements a method for generating ultra-long novel texts, ensuring a rigorous structure and continuous content.","selected":false,"bibtex":"$1f"},{"id":"xiao2024cora","title":"Cora: Optimizing low-rank adaptation with common subspace of large language models","authors":[{"name":"Xiaojun Xiao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Sen Shen","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Qiming Bao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hongfei Rong","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Kairui Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zhongsheng Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiamou Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:6:tags","researchArea":"machine-learning","journal":"","conference":"arXiv preprint arXiv:2409.02119","abstract":"$20","description":"Introduces CoRA, a method for improving Low‑Rank Adaptation (LoRA) by replacing one of its matrices with a shared subspace across tasks, reducing parameters while maintaining or improving fine‑tuning performance.","selected":false,"bibtex":"$21"},{"id":"wang2024weak","title":"Weak Supervision Techniques towards Enhanced ASR Models in Industry-level CRM Systems","authors":[{"name":"Zhongsheng Wang","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Sijie Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jia Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yung-I Liang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yuxi Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jiamou Liu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:7:tags","researchArea":"machine-learning","journal":"","conference":"International Conference on Neural Information Processing","pages":"138--152","doi":"10.1007/978-981-96-7036-9_10","abstract":"In the design of customer relationship management (CRM) systems, accurately identifying customer types and offering personalized services are key to enhancing customer satisfaction and loyalty. However, this process faces the challenge of discerning customer voices and intentions, and general pre‑trained automatic speech recognition (ASR) models make it difficult to effectively address industry‑specific speech recognition tasks. To address this issue the authors propose a solution for fine‑tuning industry‑specific ASR models using weak supervision, which significantly improves the performance of the fine‑tuned ASR models in industry applications. Experimental results show that this method substantially improves the crucial auxiliary role of the ASR model in industry CRM systems, and the approach has also been adopted in actual industrial applications.","description":"Presents a weak‑supervision strategy for fine‑tuning automatic speech recognition models tailored to customer relationship management systems, leading to significant improvements in identifying customer voices in industry applications.","selected":false,"bibtex":"$22"}]}],false,false]}]
c:null
10:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
b:null
14:{"metadata":[["$","title","0",{"children":"Publications | Zhongsheng Wang 王钟声"}],["$","meta","1",{"name":"description","content":"A collection of my research work."}],["$","meta","2",{"name":"author","content":"Zhongsheng Wang"}],["$","meta","3",{"name":"keywords","content":"Zhongsheng Wang,PhD,Research,University of Auckland"}],["$","meta","4",{"name":"creator","content":"Zhongsheng Wang"}],["$","meta","5",{"name":"publisher","content":"Zhongsheng Wang"}],["$","meta","6",{"property":"og:title","content":"Zhongsheng Wang 王钟声"}],["$","meta","7",{"property":"og:description","content":"Second-year PhD student at University of Auckland."}],["$","meta","8",{"property":"og:site_name","content":"Zhongsheng Wang's Academic Website"}],["$","meta","9",{"property":"og:locale","content":"en_US"}],["$","meta","10",{"property":"og:type","content":"website"}],["$","meta","11",{"name":"twitter:card","content":"summary"}],["$","meta","12",{"name":"twitter:title","content":"Zhongsheng Wang 王钟声"}],["$","meta","13",{"name":"twitter:description","content":"Second-year PhD student at University of Auckland."}],["$","link","14",{"rel":"icon","href":"/fav.png"}]],"error":null,"digest":"$undefined"}
e:{"metadata":"$14:metadata","error":null,"digest":"$undefined"}
